{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Importation et lecture de fichier :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-33b8592c3f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGloVe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               tweet result\n",
       "0   @melo_gabby Sao os assuntos mais comentados d...    irr\n",
       "1   @Marbelle30 ...Esta familia de #twitter cada ...    irr\n",
       "2   @apple please bring back the old Siri app for...    neu\n",
       "3   Oef..#Microsoft trapt Google Toolbar uit #Sky...    neu\n",
       "4                  I â™¥ @Apple http://t.co/a8on3IAa\\n    pos"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@melo_gabby Sao os assuntos mais comentados d...</td>\n      <td>irr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Marbelle30 ...Esta familia de #twitter cada ...</td>\n      <td>irr</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@apple please bring back the old Siri app for...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Oef..#Microsoft trapt Google Toolbar uit #Sky...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I â™¥ @Apple http://t.co/a8on3IAa\\n</td>\n      <td>pos</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    " filepath = \"data/eit_annot_100_1899.txt\"\n",
    " with open(filepath, \"r\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "info = [x.split(\")\")[0] for x in content]\n",
    "\n",
    "# Get only the line where the author = author\n",
    "idx_consensus = np.array([y.split(\",\")[2] for y in info])\n",
    "idx_consensus = np.where(idx_consensus == \"consensus\")\n",
    "\n",
    "results = np.array([y.split(\",\")[1] for y in info])[idx_consensus]\n",
    "\n",
    "# tweets\n",
    "tweets = np.array([x.split(\")\")[1] for x in content])[idx_consensus]\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['tweet'] = tweets\n",
    "df['result'] = results\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I am king\n"
     ]
    }
   ],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    \n",
    "    return url.sub('', text)\n",
    "\n",
    "example = 'New competition launched: https://www.kaggle.com/c/nlp-getting-started'\n",
    "\n",
    "remove_URL(example)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    return text.translate(table)\n",
    "\n",
    "example = \"I am #king\"\n",
    "print(remove_punct(example))\n",
    "\n",
    "remove_emoji(\"Omg another Earthquake ðŸ˜”ðŸ˜”\")\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    sentence_words = sentence.split(' ')\n",
    "    new_sentence_words = list()\n",
    "    \n",
    "    for sentence_word in sentence_words:\n",
    "        sentence_word = sentence_word.replace('#', '')\n",
    "        new_sentence_word = wnl.lemmatize(sentence_word.lower(), wordnet.VERB)\n",
    "        new_sentence_words.append(new_sentence_word)\n",
    "        \n",
    "    new_sentence = ' '.join(new_sentence_words)\n",
    "    new_sentence = new_sentence.strip()\n",
    "    \n",
    "    return new_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_c'] = df['tweet'].apply(lambda x: remove_URL(x))\n",
    "df['tweet_c'] = df['tweet_c'].apply(lambda x: remove_emoji(x))\n",
    "df['tweet_c'] = df['tweet_c'].apply(lambda x: remove_punct(x))\n",
    "df['tweet_c'] = df['tweet_c'].apply(lambda x: lemmatize_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               tweet result  \\\n",
       "0   @melo_gabby Sao os assuntos mais comentados d...    irr   \n",
       "1   @Marbelle30 ...Esta familia de #twitter cada ...    irr   \n",
       "2   @apple please bring back the old Siri app for...    neu   \n",
       "3   Oef..#Microsoft trapt Google Toolbar uit #Sky...    neu   \n",
       "4                  I â™¥ @Apple http://t.co/a8on3IAa\\n    pos   \n",
       "5   RT @NeowinFeed: Steve Ballmer slams Android #...    neu   \n",
       "6   Is #Google Down? http://t.co/wFrzKYsN via @Ej...    neu   \n",
       "7   This is better than *every* magazine having t...    pos   \n",
       "8   RT @mpastrana: RT @apple no pasa nada, todo e...    irr   \n",
       "9   Many new features for Android. #NexusPrime #G...    neu   \n",
       "\n",
       "                                             tweet_c  \n",
       "0  melogabby sao os assuntos mais comentados do m...  \n",
       "1  marbelle30 esta familia de twitter cada vez cr...  \n",
       "2  apple please bring back the old siri app for u...  \n",
       "3        oefmicrosoft trapt google toolbar uit skype  \n",
       "4                                           i  apple  \n",
       "5  rt neowinfeed steve ballmer slam android micro...  \n",
       "6  be google down  via ejunkie good for bing micr...  \n",
       "7  this be better than every magazine have their ...  \n",
       "8  rt mpastrana rt apple no pasa nada todo esta b...  \n",
       "9     many new feature for android nexusprime google  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>result</th>\n      <th>tweet_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@melo_gabby Sao os assuntos mais comentados d...</td>\n      <td>irr</td>\n      <td>melogabby sao os assuntos mais comentados do m...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Marbelle30 ...Esta familia de #twitter cada ...</td>\n      <td>irr</td>\n      <td>marbelle30 esta familia de twitter cada vez cr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@apple please bring back the old Siri app for...</td>\n      <td>neu</td>\n      <td>apple please bring back the old siri app for u...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Oef..#Microsoft trapt Google Toolbar uit #Sky...</td>\n      <td>neu</td>\n      <td>oefmicrosoft trapt google toolbar uit skype</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I â™¥ @Apple http://t.co/a8on3IAa\\n</td>\n      <td>pos</td>\n      <td>i  apple</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RT @NeowinFeed: Steve Ballmer slams Android #...</td>\n      <td>neu</td>\n      <td>rt neowinfeed steve ballmer slam android micro...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Is #Google Down? http://t.co/wFrzKYsN via @Ej...</td>\n      <td>neu</td>\n      <td>be google down  via ejunkie good for bing micr...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This is better than *every* magazine having t...</td>\n      <td>pos</td>\n      <td>this be better than every magazine have their ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RT @mpastrana: RT @apple no pasa nada, todo e...</td>\n      <td>irr</td>\n      <td>rt mpastrana rt apple no pasa nada todo esta b...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Many new features for Android. #NexusPrime #G...</td>\n      <td>neu</td>\n      <td>many new feature for android nexusprime google</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'TEXT' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d3d405570dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mINPUT_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mHIDDEN_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}